---
title: "PCA"
output: pdf_document
date: "2025-03-20"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggcorrplot)
library(corrr)
library(FactoMineR)
library(tidyverse)
library(leaps)
```

```{r}
lasso_filtered <- read.csv("lasso_select.csv")
testing <- read.csv("testing.csv")

lasso_filtered <- lasso_filtered %>% 
  select(-X)
```

```{r}
lasso_pca <- lasso_filtered[, -which(names(lasso_filtered) == "Ranking")]
pca_result <- prcomp(lasso_pca, scale = TRUE)
summary(pca_result)


# top 5 contributing variables for the first 10 principal components
top_vars_10 <- lapply(1:10, function(i) {
  x <- pca_result$rotation[, i]
  top_contributors <- sort(abs(x), decreasing = TRUE)[1:5]
  var_names <- names(top_contributors)
  data.frame(PC = paste0("PC", i), Variable = var_names, Loading = top_contributors)
})


top_vars_10_df <- do.call(rbind, top_vars_10)

# Print the result
print(top_vars_10_df)

list_pca <- top_vars_10_df[, 2]
```


```{r}
lasso_filtered <- lasso_filtered %>%
  mutate(CIP15BACHL = as.numeric(CIP15BACHL),
         CIP39BACHL = as.numeric(CIP39BACHL),
         CIP50BACHL = as.numeric(CIP50BACHL),
         CIP05CERT1 = as.numeric(CIP05CERT1),
         LOCALE = as.factor(LOCALE))

testing <- testing %>%
  mutate(CIP15BACHL = as.numeric(CIP15BACHL),
         CIP39BACHL = as.numeric(CIP39BACHL),
         CIP50BACHL = as.numeric(CIP50BACHL),
         CIP05CERT1 = as.numeric(CIP05CERT1),
         LOCALE = as.factor(LOCALE))
```

```{r}
# backwards selection
back_models <- regsubsets(Ranking~., data = lasso_filtered, nvmax = 30, method = "backward")
summary_back <- summary(back_models)

# save optimal model based on bic
best_model_back <- summary_back$which[which.min(summary_back$bic),]
models_backward <- summary_back$which

back_vars <- names(which(best_model_back))
print(back_vars)

# remove intercept
# selected LOCALE32 and 41
back_selected_vars <- names(which(best_model_back))[-c(1, 2, 3)]
back_selected_vars <- c(back_selected_vars, "LOCALE")
print(back_selected_vars)

# refit model with selected variables
formula_back <- as.formula(paste("Ranking ~", paste(back_selected_vars, collapse = " + ")))

# run best subsets
# best_subsets_back <- regsubsets(
#  formula_back, 
#  data = lasso_filtered,
#  nvmax = 30,
#  really.big = TRUE
#)

# best subsets gave the same model as backwards
# summary_best_back <- summary(best_subsets_back)
# summary_best_back$bic

# build model
final_model_back <- lm(formula_back, data = lasso_filtered)

# check model performance
summary(final_model_back)

# predict, round, and print
predictions_back <- predict(final_model_back, newdata = testing[, back_selected_vars])
predictions_back_rounded <- sapply(predictions_back, function(x) round(x))
print(predictions_back_rounded)

final_rank_back <- rank(predictions_back)

residual <- {}
for (i in 1:50) {
  residual[i] <-  abs(predictions_back_rounded[i] - testing_final$X2025[i])
}
sum(residual) / 100
```

```{r}
# forward selection
forw_models <- regsubsets(Ranking~., data = lasso_filtered, nvmax = 30, method = "forward")
summary_forw <- summary(forw_models)

# save optimal model based on bic
best_model_forw <- summary_forw$which[which.min(summary_forw$bic),]
models_forward <- summary_forw$which

forw_vars <- names(which(best_model_forw))

# remove intercept
# selected LOCALE12
forw_selected_vars <- names(which(best_model_forw))[-c(1, 2)]
forw_selected_vars <- c(forw_selected_vars, "LOCALE")
print(forw_selected_vars)

# refit model with selected variables
formula_forw <- as.formula(paste("Ranking ~", paste(forw_selected_vars, collapse = " + ")))

# run best subsets
best_subsets_forw <- regsubsets(
  formula_forw, 
  data = lasso_filtered,
  nvmax = 30,
  really.big = TRUE
)

# best subsets gave a different model
summary_best_forw <- summary(best_subsets_forw)
summary_best_forw$bic

# build model
final_model_forw <- lm(formula_forw, data = lasso_filtered)

# check model performance
summary(final_model_forw)

# predict, round, and print
predictions_forw <- predict(final_model_forw, newdata = testing[, forw_selected_vars])
predictions_forw_rounded <- sapply(predictions_forw, function(x) round(x))
print(predictions_forw_rounded)

final_rank_forw <- rank(predictions_forw)
```
```{r}
# build model for forward + best subsets

# save optimal model based on bic
best_model_forw_best <- summary_best_forw$which[which.min(summary_best_forw$bic),]
forw_best_vars <- names(which(best_model_forw_best))

# remove intercept (selected LOCALE13)
forw_best_vars <- names(which(best_model_forw_best))[-c(1, 28)]

# add LOCALE back
forw_best_vars <- c(forw_best_vars, "LOCALE")

# rebuild formula with selected variables
formula_forw_best <- as.formula(paste("Ranking ~", paste(forw_best_vars, collapse = " + ")))

# build model
final_model_forw_best <- lm(formula_forw_best, data = lasso_filtered)

# check model performance
summary(final_model_forw_best)

# predict, round, and print
predictions_forw <- predict(final_model_forw_best, newdata = testing[, forw_best_vars])
final_rank_forw_best <- rank(predictions_forw)

```

```{r}
# stepwise selection

step_models <- regsubsets(Ranking~., data = lasso_filtered, nvmax = 30, method = "seqrep")
summary_step <- summary(step_models)

# save optimal model based on bic
best_model_step <- summary_step$which[which.min(summary_step$bic),]

# remove them (and intercept) and add original variable back
step_selected_vars <- names(which(best_model_step))[-c(1, 2, 3, 4, 5, 6)]

# for each , extract and make it 
step_selected_vars <- c(step_selected_vars, "LOCALE", "CIP15BACHL", "CIP39BACHL", "CIP50BACHL")


# refit model with selected variables
formula_step <- as.formula(paste("Ranking ~", paste(step_selected_vars, collapse = " + ")))

# run best subsets
# best_subsets_full <- regsubsets(
#  formula, 
#  data = lasso_filtered,
#  nvmax = 30,
#  really.big = TRUE
#)

# best subsets gave the same model as stepwise
# summary_best_step <- summary(best_subsets_full)
# summary_best_step$bic

# create model from stepwise selected variables
final_model_step <- lm(formula_step, data = lasso_filtered)

# check model performance
summary(final_model_step)

# predict and save rank
predictions_step <- predict(final_model_step, newdata = testing[, step_selected_vars])
final_rank_step <- rank(predictions_step)
```

```{r}
# append results to testing
results_final <- testing_final %>%
  select(c(UNITID, INSTNM, X2025)) %>%
  mutate(actual_rank = X2025) %>%
  select(-X2025)
results_final$step_predict <- final_rank_step
results_final$forw_predict <- final_rank_forw
results_final$back_predict <- final_rank_back
results_final$forw_best_predict <- final_rank_forw_best
```
```{r}
# Comparing different rankings

# adjusted R^2
# step = 0.9711
# forw = 0.9686 
# back = 0.9682
# forw_best = 0.9674
# step > forw > back > forw_best

# spearman's rank correlation
cor(results_final$step_predict, results_final$actual_rank, method = "spearman")
cor(results_final$forw_predict, results_final$actual_rank, method = "spearman")
cor(results_final$back_predict, results_final$actual_rank, method = "spearman")
cor(results_final$forw_best_predict, results_final$actual_rank, method = "spearman")
# step > forw_best > back > forw

# mean absolute error
mae <- function(rank_vec) {
  mean(abs(rank_vec[i] - results_final$actual_rank[i]))
}
mae(results_final$step_predict)
mae(results_final$forw_predict)
mae(results_final$back_predict)
mae(results_final$forw_best_predict)
# step < back < forw < forw_best

# penalized mean absolute error (adds linear penalty, higher penalty for top ranks)
weighted_mae <- function(pred, true) {
  n <- length(true)
  weights <- rev(1:n)  # Higher weight for top ranks
  sum(weights * abs(pred - true)) / sum(weights)
}
weighted_mae(results_final$step_predict, results_final$actual_rank)
weighted_mae(results_final$forw_predict, results_final$actual_rank)
weighted_mae(results_final$back_predict, results_final$actual_rank)
weighted_mae(results_final$forw_best_predict, results_final$actual_rank)
# step < forw < forw_best < back

# kendall's tau correlation
cor(results_final$step_predict, results_final$actual_rank, method = "kendall")
cor(results_final$forw_predict, results_final$actual_rank, method = "kendall")
cor(results_final$back_predict, results_final$actual_rank, method = "kendall")
cor(results_final$forw_best_predict, results_final$actual_rank, method = "kendall")
# step > forw_best > back > forw

# levenshtein distance (edit distance)

# install.packages("stringdist")
library(stringdist)
mean(stringdist(results_final$step_predict, results_final$actual_rank, method = "lv"))
mean(stringdist(results_final$forw_predict, results_final$actual_rank, method = "lv"))
mean(stringdist(results_final$back_predict, results_final$actual_rank, method = "lv"))
mean(stringdist(results_final$forw_best_predict, results_final$actual_rank, method = "lv"))
# step < forw_best < back < forw
# write.csv(results_final, "final_predictions.csv")
```


```{r}
# compare pca with stepwise

length(list_pca)
length(intersect(back_vars, list_pca))
length(intersect(forw_vars, list_pca))
length(intersect(step_selected_vars, list_pca))
length(intersect(forw_best_vars, list_pca))

length(intersect(back_vars, forw_vars))
length(intersect(back_vars, step_selected_vars))
length(intersect(step_selected_vars, forw_vars))

combined_list <- unique(c(back_vars, forw_vars, step_selected_vars))
length(combined_list)

length(unique(c(combined_list, list_pca)))
length(intersect(combined_list, list_pca))
```

```{r}
# create dictionary and append stepwise model coefficient to it
full_dictionary <- readxl::read_excel("CollegeScorecardDataDictionary.xlsx", sheet = 4)

dictionary <- full_dictionary %>%
  select(c("NAME OF DATA ELEMENT", "VARIABLE NAME")) %>% na.omit("VARIABLE NAME") %>%
  filter(`VARIABLE NAME` %in% step_selected_vars)

coefficients <- as.data.frame(coef(final_model_step)) %>%
  tibble::rownames_to_column(var = "Variable") %>%
  rename(Coefficient = 2) 
coefficients <- coefficients[-1,]

coefficients_final <- coefficients %>%
  mutate(abs_coef = abs(Coefficient)) %>%
  mutate(weights = 100 * abs_coef / sum(abs_coef)) %>%
  mutate(weights_rounded = round(weights, 2))

final_dictionary <- full_join(dictionary, coefficients_final, by = c("VARIABLE NAME" = "Variable"))

final_dictionary <- final_dictionary %>%
  mutate(impact = ifelse(Coefficient > 0, "neg", "pos")) %>%
  select(c(`NAME OF DATA ELEMENT`, impact, weights_rounded, Coefficient, `VARIABLE NAME`))

# factors that improve ranking
final_dictionary %>%
  filter(impact == "pos") %>%
  print(`NAME OF DATA ELEMENT`)

# factors that reduce ranking
final_dictionary %>%
  filter(impact == "neg") %>%
  print(`NAME OF DATA ELEMENT`)

# write.csv(final_dictionary, "final_dictionary.csv")
```

```{r}
# Create a dataframe with the extracted table
usnews_formula <- data.frame(
  Indicator = c("Graduation rates", "First-year retention rates", "Graduation rate performance", 
                "Pell graduation rates", "Pell graduation performance", "First-generation graduation rates",
                "First-generation graduation rate performance", "College grads earning more than a high school grad",
                "Borrower debt", "Peer assessment", "Financial resources per student", "Faculty salaries",
                "Full-time faculty", "Student-faculty ratio", "Standardized tests", "Citations per publication",
                "Field-Weighted Citation Impact", "Publication share in the Top 5% of Journals by CiteScore",
                "Publication share in the Top 25% of Journals by CiteScore", "TOTAL"),
  
  `schools_with_sat/act_2025` = c(16, 5, 10, 5.5, 5.5, 0, 0, 5, 5, 20, 8, 6, 2, 3, 5, 1.25, 1.25, 1, 0.5, 100),
  
  `schools_without_sat/act_2025` = c(21, 5, 10, 5.5, 5.5, 0, 0, 5, 5, 20, 8, 6, 2, 3, 0, 1.25, 1.25, 1, 0.5, 100),
  
  `2024 Weight` = c(16, 5, 10, 3, 3, 2.5, 2.5, 5, 5, 20, 8, 6, 2, 3, 5, 1.25, 1.25, 1, 0.5, 100)
)

# Save as CSV
# write.csv(usnews_formula, "us_news_formula.csv", row.names = FALSE)
```
