---
title: "STA-310 remake data cleaning"
output: pdf_document
date: "2025-03-20"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r}
# read dataframe
top100data <- read.csv("top100data.csv")
ranking <- read.csv("rankings.csv")
```

```{r}
# get top 100 ranked schools from the 2025 ranking data that we're predicting for
ranking100 <- ranking %>%
  filter(as.numeric(X2025) <= 100)
```

```{r}
# remove columns that have all same data
all_same_columns <- sapply(top100data, function(x) length(unique(x)) == 1)
data_top100 <- top100data[, !(all_same_columns)] # this gives 2987 variables

# make PS NA before filtering
data_top100[] <- as.data.frame(sapply(data_top100, function(col) ifelse(col == "PS", NA, col)))

# print check that PS is not there
# print(data_top100$ENRL_4YR_TRANS_YR2_RT)

# remove if all NA

data_top100 <- data_top100[,colSums(is.na(data_top100))<nrow(data_top100)]

# TODO: for each school, replace missing numeric data with the average value 

# make variables numeric

data_top100 <- data_top100 %>%
  mutate(across(12:ncol(.), as.numeric))

# calculate whole mean

overall_means <- data_top100 %>%
  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %>% 
  as.list()

# add missing values

clean_data_top100 <- data_top100 %>%
  group_by(UNITID) %>%
  mutate(across(where(is.numeric), ~ {
    # if all is na replace with overall means
    if (all(is.na(.))) {
      
      overall_means[[cur_column()]]
    } else {
      # otherwise replace na with group mean
      ifelse(is.na(.), mean(., na.rm = TRUE), .)
    }
  })) %>%
  ungroup()

# check NA

colSums(is.na(clean_data_top100))

```

```{r}
# calculate proportion of NA
missing_proportions <- colMeans(is.na(data_top100))

# filters out variables with given threshold
threshold <- 0.1
data_top100_filtered <- data_top100[, missing_proportions <= threshold]
```

```{r}
# install.packages("glmnet")
library(glmnet)
library(tidyverse)

# remove 2025 data from training data
training <- data_top100_filtered %>%
  filter(Year != 2025)

ranking_training <- ranking100 %>%
  select(c("IPEDS.ID", "X2024", "X2023", "X2022", "X2021"))

# pivot ranking
ranking_long <- ranking_training %>% 
  pivot_longer(cols = c(X2024, X2023, X2022, X2021), 
               names_to = "Year",
               values_to = "Ranking"
              )

# fix year variable to represent number
ranking_join <- ranking_long %>%
  mutate(Year = as.numeric(substring(Year, 2)))

# merge data and ranking
training_final <- left_join(training, ranking_join, by = c("UNITID" = "IPEDS.ID", "Year" = "Year")) %>% na.omit(Ranking)

training_final$Ranking <- as.numeric(training_final$Ranking)

training_final <- training_final %>% 
  na.omit(Ranking)

sum(is.na(training_final$Ranking))

training <- subset(training_final, select = -c(Ranking, UNITID, Year, OPEID, OPEID6, INSTNM))

training_matrix <- data.matrix(training)

# Check for missing values
if (any(is.na(training_final$Ranking))) {
  stop("Missing values found in y. Please handle them.")
}

# Check for constant values within a fold
if (length(unique(training_final$Ranking)) == 1) {
  stop("y is constant within this fold. Please ensure sufficient variation.")
}

cv.lasso <- cv.glmnet(training_matrix, training_final$Ranking, alpha=1)  # alpha=1 for Lasso
plot(cv.lasso)

best.lambda <- cv.lasso$lambda.min

lasso.model <- glmnet(training_matrix, training_final$Ranking, alpha=1, lambda=best.lambda)
lasso_select <- coef(lasso.model)

# 101 variables chosen
```


```{r}
# filter out those with all unique values or all same values, besides the id column (UNITID)
id_column <- "UNITID" 

unique_columns <- sapply(data_top100, function(x) length(unique(x)) == nrow(data_top100))

data_top100_filtered <- data_top100[, !(unique_columns & names(data_top100) != id_column)]
# this didn't remove anything
```


